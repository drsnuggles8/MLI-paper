\documentclass{article}
\usepackage{amsmath,amsfonts,amsthm,color,amssymb,mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\newtheorem{assumption}{Assumption}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\usepackage[normalem]{ulem}
\newtheorem{example}{Example}
\usepackage[ruled, linesnumbered]{algorithm2e}
\usepackage{geometry}
\usepackage{enumerate}
\usepackage{bm}
\usepackage{subcaption}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{matrix,shapes,chains,positioning,decorations.pathreplacing,arrows}
\usepackage{todonotes}
\usepackage{parskip}

\newcommand{\EE}{\mathbb{E}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\Ee}{\mathcal{E}}
\newcommand{\Hh}{\mathcal{H}}
\newcommand{\Nn}{\mathcal{N}}
\newcommand{\Tt}{\mathcal{T}}
\newcommand{\R}{\mathrm{R}}
\newcommand{\F}{\mathrm{F}}
\newcommand{\m}{\mathrm{m}}
\newcommand{\VIX}{\mathrm{VIX}}
\newcommand{\osig}{\overline{\sigma}}
\newcommand{\ind}{1\hspace{-2.1mm}{1}}
\newtheorem{definition}{Definition}
\def\blue#1{\textcolor{blue}{#1}}
\def\red#1{\textcolor{red}{#1}}
\def\green#1{\textcolor{green}{#1}}
\def\magenta#1{\textcolor{magenta}{#1}}
\DeclareMathOperator*{\argmin}{\arg\!\min}

% Commands
\newcommand{\varphinn}{\varphi_\textrm{NN}}
\newcommand{\varphitilde}{\tilde{\varphi}}
\newcommand{\dd}{\ensuremath{\mathrm{d}}}
\newcommand{\E}{\mathbb{E}}
\newcommand*\colvec[3][]{
	\begin{pmatrix}\ifx\relax#1\relax\else#1\\\fi#2\\#3\end{pmatrix}
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathOperator{\diag}{diag}

\begin{document}
\title{Experiments on the neural architecture for deep calibration of (rough) stochastic volatility models}

\renewcommand\footnotemark{}
\author{Ole Bueker\\
\large{Commerzbank AG}\\
\normalsize{ole.bueker@commerzbank.com}
}
\maketitle

\begin{abstract}
  % REWRITE THE WHOLE ABSTRACT AT THE END
  Swift calibration of accurate financial models that can represent the realities of the market has been an important topic.
  Techniques from deep learning play a more and more important role for the important task of calibration of financial models. The pioneering paper by Hernandez [Risk, 2017] was a catalyst for resurfacing interest in research in this area. In this paper we
  advocate an alternative (two-step) approach using deep learning techniques solely to learn the pricing map -- from
  model parameters to prices or implied volatilities -- rather than directly the calibrated model parameters as a function of observed market data.  Having a fast and accurate neural-network-based approximating pricing map (first step), we can then (second step) use traditional model calibration algorithms. In this work we showcase a direct comparison of different potential approaches to the learning stage and present algorithms that provide a sufficient accuracy for practical use.
  We provide a first neural network-based calibration method for rough volatility models for which calibration can be done on the fly.
  We demonstrate the method via a hands-on calibration engine on the rough Bergomi model, for which classical
  calibration techniques are difficult to apply due to the high cost of all known numerical pricing methods.  Furthermore, we display and compare different types of sampling and training methods and elaborate on their advantages under different objectives. As a further application we use the fast pricing method for a Bayesian analysis of the calibrated model.
\end{abstract}

\noindent \textbf{2020 }\textit{Mathematics Subject Classification}: 60G15, 60G22, 91G20, 91G60\\
\noindent \textbf{Keywords: }Rough volatility, volatility modelling, Volterra process, machine learning, accurate price approximation, calibration, model assessment, Monte Carlo

\tableofcontents
\newpage

\section{Introduction}
The Black-Scholes option pricing model, introduced nearly half a century ago, remains a cornerstone of financial theory and practice,
renowned for its analytical tractability and closed-form solutions for both option prices and their sensitivities (the \emph{Greeks}).
This model has become a fundamental tool for pricing and hedging European options in financial markets.
One of its key applications is in transforming option prices to implied volatilities, a process that facilitates
the comparison of different options and the construction of implied volatility (IV) surfaces.

Implied volatility surfaces, derived by converting market prices of European options into implied volatilities,
exhibit complex patterns across different strikes (moneyness) and maturities.
These surfaces often display well-documented features such as volatility smiles and skews,
indicating that implied volatilities vary with the level of the strike price and time to maturity,
rather than remaining constant as assumed by the Black-Scholes model.
For instance, at-the-money (ATM) skews and the volatility smile highlight discrepancies between the model's predictions
and observed market behavior. Empirical studies, such as those by Bayer, Friz, and Gatheral \cite{BFG15}, have documented these phenomena
and reported specific behaviors like the power-law nature of the ATM volatility skew as maturity approaches zero.

The accurate modeling of implied volatility is crucial because it directly affects the pricing, hedging, and risk management of options
and other derivative securities.
An inaccurate model can lead to significant mispricing, which in turn can cause substantial financial losses
and ineffective risk management strategies.
The financial industry relies on robust models to value complex financial products,
manage portfolios, and ensure regulatory compliance.
Hence, the limitations of the Black-Scholes model in capturing the true nature of market volatility necessitate
the exploration and development of more sophisticated models.

To address the inadequacies of the Black-Scholes model, a variety of stochastic volatility models have been developed.
Notable among these are the SABR (Stochastic Alpha, Beta, Rho) model and the Heston model.
The SABR model incorporates stochastic volatility and can capture the dynamic behavior of the volatility smile,
while the Heston model introduces a mean-reverting stochastic variance process.
These models improve upon the Black-Scholes framework by allowing volatility to change over time,
thereby providing a better fit to market data.
Besides their superior accuracy, one of the decisive features is the tractability of the models, explaining why the SABR
(with the SABR asymptotic formula, \cite{Hagan1}) and Heston (with Fourier pricing, \cite{Hes93}) have become a mainstay at fixed income desks.
However, these models still exhibit limitations.
For example, the Heston model may struggle with accurately modeling the volatility skew for very short maturities,
and the SABR model can be computationally intensive and challenging to calibrate in certain market conditions.

In light of these challenges, rough stochastic volatility models, introduced by Bayer, Friz and Gatheral \cite{BFG15},  have gained prominence.
These models, such as the rough Bergomi model, are characterized by volatility processes with H\"older regularity lower
than that of Brownian motion, typically modeled using fractional Brownian motion with a Hurst parameter less than 0.5.
This approach captures the observed roughness in volatility time series and aligns more closely with empirical market data.
Rough volatility models effectively address the shortcomings of traditional diffusion models by providing a more accurate
representation of the observed power-law behavior of volatility skews as maturity approaches zero (\cite{AlosLeon, BFG15, BFGHS, Fukasawa}).
However, the complexity and non-Markovian nature of these models present significant computational challenges,
particularly in the calibration process.

% ADD SOME SOURCES yo
Calibrating rough volatility models is computationally intensive due to the need for precise and numerous evaluations
of the pricing function, which is often achieved through Monte Carlo simulations.
The non-Markovian nature of fraction Brownian motion exacerbates this complexity, as it introduces dependencies
that are not present in simpler, Markovian models.
To mitigate these challenges, researchers have explored various methods such as variance-reduced Monte Carlo techniques and asymptotic expansions.
Variance-reduced Monte Carlo methods aim to decrease the variance of the simulation outputs, thereby requiring fewer simulations to achieve the same accuracy (\cite{BFGMS17, BFG15, HJM17, MP18}).
Asymptotic expansions attempt to approximate the pricing function by expanding it in a series around a known solution, reducing the need
for full-scale simulations (\cite{BFGHS, FZ17}).
Despite these advancements, the calibration of rough volatility models remains prohibitively slow for practical, real-time applications.
These methods, while helpful, do not fully overcome the inherent computational complexity associated with the roughness
of the volatility process and the non-Markovian nature of the models.

To resolve these issues, Horvath, Muguruza and Tomas \cite{HMM19} proposed a deep neural network based calibration approach for rough stochastic volatility models.
They shift the calibration bottleneck to an off-line approximation of the pricing functions, in a two step approach,
which builds upon the pioneering paper of Hernandez \cite{Hernandez}.
In their work \cite{HMM19}, as well as their earlier work \cite{BHMST19}, they showed that the two step approach
allows an explainable neural network-based calibration method for rough volatility models in a reasonable time.
For a more complete review on the applications of machine learning for quantitative finance, we refer to Ludkovski \cite{Ludkovski}.
In our work, we confirm their findings, bring their code to a more modern approach that will work with the latest Python versions and libraries.
We also display and compare different neural network structures.

% REMOVE/REWRITE THIS PART
% rough vol models: \cite{AlosLeon, Fukasawa, GJR14}, we have
% log realized volatility has H\"older regularity $\approx 0.1$ \cite{BLP16, GJR14}

The paper is organised as follows:
In Section~\ref{sec:model-calibration} we present an neural network-based point of view on model calibration in finance,
as well as recalling some aspects of neural network training.
In Section~\ref{sec:pricing} we give an overview of applications of techniques from deep learning to model calibration,
covering both the one step approach of Hernandez \cite{Hernandez} as well as the two stop alternatives (\cite{HMM19}, \cite{BHMST19}).
In Section~\ref{sec:implementation} we focus on the concrete implementation of the two step approach,
both for the learning and for the actual calibration stage.

\section{Model calibration}
\label{sec:model-calibration}

Broadly speaking, calibration involves adjusting the model parameters so that the model's output matches 
observed market data.
Specifically, in the context of financial modeling, this process tunes the model parameters to fit an empirical implied volatility surface,
derived by transforming liquid European option market prices into Black-Scholes implied volatilities.
One common approach to achieve this is to minimize the weighted squared differences between the
implied volatilities of $N \in \mathbb{N}$ plain vanilla European options as predicted by the model and those observed in the market.

Consider a model $\mathcal{M} := \mathcal{M}(\theta)_{\theta \in \Theta}$, where $\theta$ are the parameters
in the parameter set $\Theta \subset \mathbb{R}^n,$ for some $n \in \mathbb{N}$.
The model $\mathcal{M}(\theta)$, and in turn the generated prices, is fully specified by the choice of their parameters.
Define the \emph{pricing map} $P$:
\begin{equation*}
\mathcal{M}(\theta, \zeta) \mapsto \mathbb{R}^m,
\end{equation*}
where $\zeta: (C(\mathbb{R}) -> \mathbb{R}^m), \,m \in \mathbb{N}$ represents the financial products we aim to price,
e.g., vanilla options for various maturities and strikes.
Market prices $\mathcal{P}^{MKT}(\zeta) \in \mathbb{R}^m, \, m \in \mathbb{N}$ are given for options described by $\zeta$ for a finite subset
$\zeta \in Z^\prime \subset Z$ of all possible option parameters.

Calibration aims to find a model parameter $\theta$ that minimizes a chosen distance metric $\delta(\cdot, \cdot)$
between model prices $\left( P(\theta, \zeta) \right)$
and market prices $\left(\mathcal{P}^{MKT}(\zeta) \right)$:
\begin{equation}\label{calibration_equation}
\widehat{\theta} = \argmin_{\theta \in \Theta} \delta\left( P(\mathcal{M}(\theta), \zeta) \right),
\left(\mathcal{P}^{MKT}(\zeta) \right)
\end{equation}

In many practical financial models, the pricing map $P(\theta, \zeta)$ used in \ref{calibration_equation} cannot be analytically determined
and must be approximated numerically.
Therefore, the calibration often involves solving an approximate $\delta$-calibration problem:
\begin{equation}\label{approximate_calibration_equation}
\widehat{\theta} = \argmin_{\theta \in \Theta} \delta\left( \tilde{P}(\mathcal{M}(\theta), \zeta), \mathcal{P}^{MKT}(\zeta) \right),
\end{equation}
where $\tilde{P}$ is a numerical approximation of the pricing map $P$.
This type of calibration is the focus in the numerical experiments discussed later in this paper (Section ~\ref{sec:implementation}),
where synthetic training samples are generated using $\tilde{P}$ to train a neural network for approximating pricing maps.
The accuracy of the neural network approximation is contingent upon the quality of the original numerical approximations.

In this work, we are specifically dealing with the rough Bergomi model.
When represented in the abstract model framework introduced above, the rough Bergomi model \cite{BFG15} is represented by
$\mathcal{M}^{\mathrm{rBergomi}}(\Theta^{\mathrm{rBergomi}})$,
with parameters $\theta = (\xi_0,\eta,\rho,H) \in \Theta^{\mathrm{rBergomi}}$.

On a given filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t){t \ge 0}, \mathbb{P})$, the model
corresponds to the following system
\begin{subequations}
  \label{eq:rbergomi}
  \begin{align}
    dX_t & =-\frac{1}{2} V_t dt +\sqrt{V_t} dW_t,\quad \textrm{for} \ t>0, \quad X_0=0, \\
    V_t  & =\xi_0(t)\mathcal{E}\left(\sqrt{2H}\eta \int_0^t
          (t-s)^{H-1/2}dZ_s\right),\quad \textrm{for} \ t>0, \quad V_0=v_0>0, 
  \end{align}
\end{subequations}
where $H \in (0,1)$ denotes the Hurst parameter, $\eta>0$,
$\mathcal{E}(\cdot)$ the stochastic exponential,
and $\xi_0(\cdot) >0$ denotes the initial forward variance curve (see \cite[Section 6]{BergomiBook}),
and $W$ and $Z$ are correlated standard Brownian motions with correlation parameter $\rho\in [-1,1]$.
This is the same setup as in \cite{HMM19}, and, just like them, we approximate the initial forward variance curve $\xi_0 (\cdot) > 0$
by a piecewiese constant function to fit the model parameters into the abstract model framework $\Theta^{\mathrm{rBergomi}}$.

\section{Deep calibration}
\label{sec:pricing}
In the following sections we
elaborate on the objectives and advantages of this two step calibration
approach and present examples of neural network architectures, precise
numerical recipes and training procedures to apply the two step calibration
approach to a family of stochastic volatility models. We also present some
numerical experiments and report the learning errors compared to chosen parameters of the synthetic data.

There are several advantages of separating the tasks of pricing and
calibration. Above
all, the most appealing reason is that it allows us to build upon the
knowledge we have gained about the models in the past decades, which is of
crucial importance from a risk management perspective. By its very design,
\textbf{(i)} deep learning the \emph{price approximation} combined with
\textbf{(ii)} deterministic calibration does not cause more headache to risk
managers and regulators than the corresponding stochastic models do.
Designing the training as described above demonstrates how deep learning
techniques can successfully extend the toolbox of financial engineering,
without imposing the need for substantial changes in our risk management libraries.

\subsection{One-step approach: Deep calibration by the inverse map}
\label{sec:hernandez}
A more and more popular approach in quantitative finance (and many other
fields of engineering) is to develop purely data-driven frameworks, without
relying on formal models. This approach leaves the meaning of calibrated network
parameters unexplained, not to mention the ambiguity about the choice of the
number of network parameters and network design. This can cause major
challenges towards today's regulatory requirements. In addition, issues of
generalizability -- how can one price exotic options in a network trained with
vanilla option data, to give a simple example -- are difficult to analyse, and
traditional paradigms of finance -- such as no arbitrage -- are hard to
guarantee in the absence of a model.

A second, more model based approach was proposed in the pioneering work of
Hernandez \cite{Hernandez}, followed by several other authors such as
Stone~\cite{Stone}, Dimitroff, R\"oder and Fries~\cite{HestonConvolutional} and
many others. A main characteristic of the neural network proposed by
\cite{Hernandez} is that option price approximation and parameter calibration
are done in one step within the same network.
Indeed, the idea is to directly learn the whole calibration problem, i.e., to
learn the model parameters as a function of the market prices (typically
parametrized as implied volatilities). In the formulation of
Section~\ref{sec:an-abstract-view}, this means that we learn the mapping
\begin{equation*}
  \Pi^{-1}: \left( \mathcal{P}(\zeta) \right)_{\zeta \in Z^\prime} \mapsto \widehat{\theta}.
\end{equation*}
More precisely, \cite{Hernandez} trains a deep neural network based on
labelled data $(x_i, y_i)$, $i = 1, \ldots, N$, with
\begin{equation*}
  x_i = \left( \mathcal{P}(\zeta) \right)_{\zeta \in Z^\prime_i}
\end{equation*}
for day $t_i$ (in the past) and the corresponding labels
\begin{equation*}
  y_i = \widehat{\theta}_i,
\end{equation*}
obtained from calibrating the model to the market data $y_i$ using traditional
calibration routines. The number of labelled data points $N$ is, of course,
limited to the amount of (reliable) historical market price data available.

In spite of the promising results by Hernandez \cite{Hernandez} the main
drawback of this approach, as Hernandez observes, is the lack of control on
the function $\Pi^{-1}$. Furthermore, from a risk management
perspective one has no guarantee how well the learned mapping of
$\Pi^{-1}$ will solve the calibration problem when exposed to unseen
data. In fact, this is the behaviour observed in Hernandez \cite{Hernandez},
since the out of sample performance tends to differ from the in sample one,
suggesting a not fully satisfactory generalisation of the learned map. We
recover the same behaviour of the inverse map in our own experiments, which we
included in Appendix \ref{sec:Inverse Map}.

\subsection{Two-step approach: Learning the implied volatility map of models}
\label{sec:separation}

The two step approach is somewhere mid-way between a sole reliance on
traditional pricing methods (Monte Carlo, finite elements, finite differences,
Fourier methods, asymptotic methods etc.) and the direct approach described
above that calibrate directly to the price data. Here, one separates the
calibration procedure as described in Section~\ref{sec:an-abstract-view}
\textbf{(i)} We first learn (approximate) the pricing map by a neural network
that maps parameters of a stochastic model to prices or implied
volatilities. In other words, we set up and train (off-line) a neural network
to learn the pricing map $P$.  In a second step \textbf{(ii)} we calibrate
(on-line) the model -- as approximated by the neural network trained in step
\textbf{(i)} -- to market data using a standard calibration routine. To
formalise the two step approach, for an option parametrized by $\zeta$ and a
model $\mathcal{M}$ with parameters $\theta \in \Theta$ we write
$\widetilde{P}(\theta, \zeta) \approx P(\theta, \zeta)$ for the approximation
$\widetilde{P}$ of the true pricing map $P$ based on a neural network. Then,
in the second step, for a properly chosen distance function $\delta$ (and a
properly chosen optimization algorithm) we calibrate the model by computing
\begin{equation}\label{eq:ModelCalibration}
  \widehat{\theta} = \argmin_{\theta \in \Theta} \delta\left( \left(
      \widetilde{P}(\theta, \zeta) \right)_{\zeta \in Z^\prime}, \left(
      \mathcal{P(\zeta)} \right)_{\zeta \in Z^\prime} \right).
\end{equation}
In principle, this method is not unlike traditional calibration routines, as
the true option price has to be numerically approximated for all but the most
simple models. This particular approximation method tends to be orders of
magnitudes faster compared to other numerical approximation methods for all
tested models. In particular, note that the (slow) training stage of the
neural network itself only has to be done once. We will come back to
comparisons of actual computational times in the numerical section of this
paper. 

At this stage, we note that the deep calibration routine is not yet specified
in any details: apart from purely numerical details such as the choice of the
architecture of the neural networks, the loss functions and optimization
algorithms of both the training of the neural networks in stage \textbf{(i)}
and the actual calibration in stage \textbf{(ii)}, one particularly important
choice is whether the neural network learns implied volatilities of individual
options or rather a full implied volatility surface. Before discussing these
details, let us already highlight some of the differences to the one-step
approach of \cite{Hernandez}. While the one-step approach is probably marginally
faster, we see the main benefit of the two-step approach in the increased
stability, which is influenced by two key differences:
\begin{itemize}
\item As the neural network is only responsible for option pricing in the
  model, synthetic data can (and should) be used for training. Hence, we can
  easily increase the number of training data, and the training data are
  completely unpolluted from market imperfections.
\item The two-step approach induces a natural decomposition of the overall
  calibration error into a pricing error (from the neural network) and a model
  misfit to the market data. Hence, the performance of the neural network
  itself is generally independent of changing market regimes -- which might,
  of course, change the suitability of the model under consideration.
\end{itemize}
These points, in particular, imply that frequent re-training of the neural
network is not needed in the two-step approach.




\subsubsection{The two step approach: Pointwise training and implicit and grid-based training}

The underlying principle of the two-step approach appears in one way or another in a number of related contributions 
De Spiegeleer, Madan, Reyners and Schoutens~\cite{MadanSchoutens} and McGhee \cite{McGhee}. In fact, the early works of Hutchinson, Lo and Poggio \cite{Hutchison94} and the more recent work of Culkin and Das \cite{CulcinDas17}--where Deep Neural Networks are applied neural to learn the Black-Scholes formula--can be recognised as Step \textbf{(i)} of the two-step approach in a Black-Scholes context.
Also Ferguson and Green \cite{FG18} examine Step \textbf{(i)} of the two-step approach in \cite{FG18} for basket options in a lognormal context and observe that the network even has a smoothing effect and increased accuracy in comparison to the underlying Monte Carlo prices. In this section, we examine its advantages and present an analysis of the objective function with the goal to enhance learning performance. Within this framework, the pointwise approach has the ability to asses the quality of $\widetilde{P}$ using Monte Carlo or PDE methods, and indeed it is superior training in terms of robustness.
\vspace*{0.5cm}\\ 
\textbf{Pointwise learning}\\

\begin{enumerate}
\item[Step (i):] Learn the map
  $\widetilde{P}(\theta,T,k)=\widetilde{\sigma}^{\mathcal{M}(\theta)}(T,k)$ -- that is in equation \eqref{eq:ModelCalibration} above we have $\zeta = (T,k)$. In the case of vanilla options ($\zeta = (T,k)$) one can rephrase this learning objective as an implied volatility problem:
 In the implied volatility problem the more informative implied volatility map $\widetilde{\sigma}^{\mathcal{M}(\theta)}(T,k)$  is learned, rather than call- or put option prices $\widetilde{P}(\theta,T,k)$. We denote the
  artificial neural network by $F(w;\theta, \zeta)$ as a function of the
  weights $w$ of the neural network, the model parameters $\theta$ and the
  option parameters $\zeta$. The optimisation problem to solve is the
  following:
  \begin{equation}
    \label{eq:general_loss}
    \widehat{\omega}:= \argmin_{w\in\mathbb{R}^n}\sum_{i=1}^{N_{\mathrm{Train}}}
    \eta_i(\widetilde{F}(w;\theta_{i},T_i,k_i)-\widetilde{\sigma}^{\mathcal{M}}(\theta_{i},T_i,k_i))^2. 
  \end{equation}
  where $\eta_i\in\mathbb{R}_{>0}$ is a weight vector.
\item[Step (ii):] Solve the classical model calibration problem 
$$\widehat{\theta} \coloneqq \argmin_{\theta\in\Theta}
  \sum_{j=1}^{m} \beta_j(\widetilde{\sigma}^{\mathcal{M}(\theta)}(\theta,T_j,k_j)-\sigma^{\mathrm{MKT}}_{\mathrm{BS}}(k_j,T_j))^2.$$
\end{enumerate}
for some user specified weights $\beta_j\in\mathbb{R}_{>0}$, where now the (numerical approximation of the) option price $\widetilde{P}(\theta,T,k)$  resp. implied volatility $\widetilde{\sigma}^{\mathcal{M}(\theta)}(T,k)$ is replaced by the DNN approximation $\widetilde{F}(\widehat{\omega}; \theta, T, k)$ obtained in Step \textbf{(i)}.



The critical part is, of course, the first step, as the second one merely
corresponds to classical calibration against liquid options. For the first
step, key issues are the choice of training data and the architecture of the
neural network. Regarding the training data, the general idea is as follows:
\begin{enumerate}
\item Choose realistic \emph{``prior''} distributions for both model
  parameters $\theta$ and option parameters $\zeta$ ($= (T,k)$ in the above
  notation). The point is that many theoretically possible parameters are very
  unlikely to ever occur in real markets, for both model and option
  parameters. Hence, it is wasteful to spend resources to learn the pricing
  map for, say, maturities in the range of hundreds of years. The simplest
  choice is to simply impose uniform distributions on truncated parameter
  ranges, but nothing prevents more ``informed'' possibilities, for instance
  taking into account historical distributions of estimated model parameter
  values or observed option parameter values.
\item Simulate model and option parameters according to the distribution
  chosen before and compute the corresponding option price or implied
  volatility, which serves as label for the respective parameter vector. The
  computation can be done for any available numerical method, for instance
  Monte Carlo simulation. As an aside, this mechanism can, of course, be used
  to produce training, testing and validation data in the sense of the machine
  learning literature.
\end{enumerate}

\begin{remark}
  Note that the above mentioned ``informed'' parameter distributions could
  also be encoded as weights into the loss function for the training of the
  neural network.
\end{remark}

\begin{remark}
  Instead of simulation of parameter values, we could also consider
  deterministic grids in the parameter space. In very high dimensional
  parameter spaces this probably becomes unfeasible due to the curse of
  dimensionality, but in the current context this approach may very well
  improve training of the neural network. We leave a comparison to future
  work.
\end{remark}

\vspace*{0.5cm}
\textbf{Implicit \& grid-based learning}

We take this idea further and design an implicit form of the pricing map that
is based on storing the implied volatility surface as an image given by a grid
of ``pixels''. This image-based representation has a formative contribution in
the performance of the network we present in Section \ref{sec:Numerics}. 

Let us denote by
$\Delta:=\{k_i,T_j\}_{i=1,\;j=1}^{n,\;\;\;\;m}$ a fixed grid of strikes and
maturities, then we propose the following two step approach:
\begin{enumerate}
\item[Step (i):] Learn the map
  $\widetilde{F}(\theta)=\{\sigma^{\mathcal{M}(\theta)}_{BS}(T_i,k_j)\}_{i=1,\;j=1}^{n,\;\;\;\;m}$
  via neural network where the input is a parameter combination
  $\theta\in\Theta$ of the stochastic model $\mathcal{M}(\theta)$ and the
  output is a $n\times m$ grid on the implied volatility surface
  $\{\sigma^{\mathcal{M}(\theta)}_{\mathrm{BS}}(T_i,k_j)\}_{i=1,\;j=1}^{n,\;\;\;\;m}$
  where $n,m\in\mathbb{N}$ are chosen appropriately (see Section
  \ref{sec:architecture}) on a predefined fixed grid of maturities and
  strikes. $\widetilde{F}$ takes values in $\mathbb{R}^L$  where
  $L=\textrm{strikes}\times \textrm{maturities} = nm$.
  The optimisation problem in the image-based implicit learning
  approach is:
  \begin{equation}\label{eq:gridbased_loss}
    \widehat{\omega}:=
    \argmin_{w\in\mathbb{R}^n}\sum_{i=1}^{N_{\mathrm{Train}}^{\mathrm{reduced}}}
    \sum_{j=1}^{L} \eta_j(\widetilde{F}(\theta_{i})_j-\sigma^{\mathcal{M}}(\theta_{i},T_j,k_j))^2, 
  \end{equation}
where 
$N_{\mathrm{Train}}=N_{\mathrm{Train}}^{\mathrm{reduced}} \times L$ and $\eta_i\in\mathbb{R}_{>0}$ is a weight vector.  
\item[Step (ii):] Solve the minimisation problem $$\widehat{\theta}:=\argmin_{\theta\in\Theta}\sum_{i=1}^L \beta_j(\widetilde{F}(\theta)_{i}-\sigma^{\mathrm{MKT}}_{\mathrm{BS}}(T_i,k_i))^2,$$ 
for some user specified weights $\beta_j\in\mathbb{R}_{>0}$
\end{enumerate}


The data generation stage for the image-based approach works as in the
point-wise approach, except that the option parameters $\zeta = (T,k)$ are, fixed and are no longer part of the learning algorithms -- except
implicitly in the output/labels of the neural network. This is why they appear in the general objective function of pointwise learning \eqref{eq:general_loss} but no longer appear in the objective function \eqref{eq:gridbased_loss} of the grid-based learning  above.
In practice, we choose a grid $\Delta$ of size $8\times 11$. By evaluating the implied volatility surface along $8\times 11$ gridpoints with $40.000$ different parameter combinations in $\Theta$ we effectively evaluate the ``fit" of the surface as a whole. In our experiments we chose a $8\times 11$ grid for practical reasons, but we are by no means limited to this number. For example, to obtain even higher accuracy, one could also choose a coarser grid, which would require longer learning time, but recall that learning only has to be done once. One advantage of a grid-based sampling is that one can re-use the same set of generated Monte Carlo paths along grid points. Once a grid is fixed one can also easily refine the grid by adding further refined points to it using the same set of Monte Carlo paths (evaluated at more time points).

Clearly, the neural network does depend on the grid $\Delta$ of option
parameters $\zeta$. Hence, we need to interpolate between gridpoints in order to be able to calibrate (in the calibration Step \textbf{(ii)}) also to such options, whose
maturity and strike do not exactly lie on the grid $\Delta$. 
While in the pointwise training the \textbf{interpolation between sampling points} is done by the network $\widetilde{F}(\theta)$ automatically (both in the model parameter space $\Theta$ and along the implied volatility surface in $\mathbb{K}\times \mathbb{T}$), in the grid-based implicit learning the network is only used for interpolation in the parameter space $\Theta$, and it is implicit in the space dimension, that is, --based on smoothness assumptions of the implied volatility surface-- we
interpolate between gridpoints of the implied-volatility surface manually, using appropriate splines. This indirect dependence of the trained network on $\Delta$ is alluded to by the name ``implicit learning''.
\vspace*{0.2cm}


\textbf{Implicit smile-based learning: \\
--And outlook towards an implicit learning with more elaborate grids and tessalations of the IV surface--}\\ We note that McGhee \cite{McGhee} follows an \emph{implicit} approach  for the lognormal SABR model, which lies somewhere between the
pointwise and the image-based approaches of Step \textbf{(i)}: There, the inputs
are $(\theta^{\mathrm{SABR}}, T, k_1, \ldots, k_{10})$, and there are ten volatility
outputs ${\sigma_1, \ldots, \sigma_{10}}$ per maturity $T$. 
Since between the reference points of the smile McGhee \cite{McGhee} also interpolates (by splines) based on a smoothness assumption of implied volatilities, we also refer to this approach as \emph{implicit} training.
The reference points $k_1, \ldots, k_{10}$ on the volatility surface are determined as a direct functional of the model parameters $\theta^{\mathrm{SABR}}$ and of the maturity $T$, that is the learning is done slice-by slice. 
This sampling technique showcases an excellent working example of a \emph{representative functional sampling} on the surface, where more samples are taken in certain regions of the surface, to ensure a good accuracy of the training in those regions (e.g. regions with higher liquidity). Though the sampling of the strikes in \cite{McGhee} is bespoke to the SABR model, it motivates the idea of \emph{representative sampling grid (or tessalation net)}, which would be desirable to achieve also in a model agnostic context. We note that the introduction of the weight vectors $\eta_i \in \mathbb{R}_{>0}$ in the objective function \eqref{eq:gridbased_loss} of the grid-wise approach has a similar effect as a higher sampling frequency of a neighbourhood/point.

\subsubsection{The role of the objective function: Pointwise training versus implicit and grid-based training}

Comparing the pointwise approach (characterised by the general objective function \eqref{eq:general_loss}) and the image-based approach (characterised
by the objective function \eqref{eq:gridbased_loss}), we find that
both of them can be advantageous in certain situations. We highlight the connection between the two below, and
elaborate on some of the respective advantages of each approach.\\

Equation \eqref{eq:gridbased_loss} can be brought to the form of
\eqref{eq:general_loss} equation by inserting (into \eqref{eq:general_loss})
the specification values $\theta = \theta^\prime$, with
$$
\theta^\prime_1 = \theta_1, \ldots, \theta^\prime_L = \theta_1,
\theta^\prime_{L+1} = \theta_2, \ldots,
$$
and recalling that
$L=\textrm{strikes}\times \textrm{maturities}$ and
$N_{\mathrm{Train}}=N_{\mathrm{Train}}^{\mathrm{reduced}} \times L$. Hence,
the pointwise approach is more general than the image-based one.


With this in mind we make the general note, many of the various advantages and disadvantages of both
approaches can, in principle, be mitigated by careful choice of the data
generation mechanism (of the training and validation datasets) and the loss
function in the training.

\begin{itemize}
\item The biggest difference, between pointwise and image based implicit learning procedures
is  that image based implicit learning requires an outside (implicit) interpolation
between the learned implied volatilities in order to compute the implied
volatility of an option with an arbitrary strike or maturity, not aligned
with the grid. At face value, this is of course an advantage of the
pointwise (explicit) approach, where the interpolation is rather performed by the deep
neural network. On the other hand, we note that the function
$(T,k) \mapsto \sigma^{\mathcal{M}}(\theta; T,k)$ (for fixed model
parameters $\theta$) is usually a very well understood smooth function. (At
least for useful models, as the market implied vol surface arguably is nice
and smooth.) This is not necessarily true for
$\theta \mapsto \sigma^{\mathcal{M}}(\theta; T,k)$, which is not nearly as
well understood for more modern sophisticated models such as rough Bergomi. Hence, we
have much more confidence in applying standard interpolation in $(T,k)$
rather than in $\theta$, which also lives in a higher dimensional
space. Hence, the outside interpolation may, in practice, not cause any
difficulties. 

\item Indeed, this very same structure induces a reduction of variance in the
training data for the image-based approach as compared to the pointwise
approach. Formally speaking, in the image based approach only the
model parameters are sampled, while the strike and maturities of the
underlying instruments are deterministic. As a side note, keep in mind that we
should always compare the two approaches based on a fixed number $N_{\mathrm{Train}}$
of total training data.

\item It is also easier to take into account the structure of real financial data
into the data generation for the pointwise approach by adjusting the (random) sampling distribution on the surface accordingly. Clearly, not all options
are equally \emph{important} for the purpose of calibration, but we would like
to concentrate on liquid options. It is easy to adjust the sampling
distribution for strikes and maturities in the pointwise approach to take into
account historical numbers of liquidity. In the grid-based approach, this can to some extent be taken into account by the choice of the weight vector $\eta_i \in \mathbb{R}_{>0}$ in \eqref{eq:gridbased_loss}, or more accurately taken into account by using non-uniform, non-tensorized, or bespoke quasirandom sampling
grids, with higher density of points in regions with higher liquidity. 


\item The image-based approach may be seen as an efficient dimension-reduction
technique as compared to the pointwise one. Indeed, as dimensions are shifted
from the input of the neural network to the output, the learning task becomes
easier since lower-dimensional. Of course, the price we pay is that we only
learn the values of the implied volatilities on a fix grid $\Delta$ of option
parameters. In this example, this price is, however, worth paying since the
regularity of the volatility surface is well understood. This implies that we
know very well the number and location of grid points required to get good
fits globally in terms of the chosen interpolation.
\end{itemize}

In the particular calibration example presented in Section \ref{sec:Numerics} below, the image-based
approach performed somewhat better than the pointwise approach, which indicates
that the variance and dimension reduction features may be more important than
the other aspects in the above comparison.

\begin{remark}
  \label{rem:chebyshev}
  In principle, the two-step approach is also amenable to other numerical
  interpolation methods. For instance, we could also use Chebyshev
  interpolation to approximate model implied volatilities such as \cite{Glau19}.
\end{remark}
\begin{remark}
  \label{rem:chebyshev-2}
  In line with Remark~\ref{rem:chebyshev}, we note that the image-based
  approach (in conjunction with the outside interpolation) is a hybrid between
  a pure DNN approximation such as the point-wise approach and a standard
  polynomial interpolation method, such as Chebyshev approximation, see
  \cite{Glau19} for example. Of course, other, more specialized interpolation
  methods on the implied volatility surface are also possible, for instance
  using the SVI volatility parameterization, see for example \cite{Itkin14}.
\end{remark}



\section{Practical implementation}
\label{sec:implementation}
We start by describing the approximation network (Step \textbf{(i)} of Section \ref{sec:pricing}  with objective functions \eqref{eq:general_loss} and \eqref{eq:gridbased_loss}) and leave the discussion of calibration (Step \textbf{(ii)}) for Section \ref{sec:calibrationStep} below.
While several realted works \cite{Hutchison94, CulcinDas17, McGhee} have demonstrated that learning the pricing map (Step \textbf{(i)}) in the Black-Scholes model and in certain clasical stochastic volatility models (such as the lognormal SABR model in \cite{McGhee}) can be done to a satisfactory accuracy with a single hidden layer, the situation is--as often--more delicate in the case of rough volatility models. Since these models are highly nonlinear nature, they also require deeper networks for an accurate approximation of their pricing functional.

\subsection{Network architecture and training}

\label{sec:architecture}
We present the architecture used for the grid-based approach in some detail,
as this approach was used for most of the numerical examples below.
\begin{enumerate}
\item A fully connected feed forward neural network with 3 hidden layers
  and $30$ nodes on each layers;
\item Input dimension = $n$, number of  model parameters
\item Output dimension = 11 strikes$\times$ 8 maturities for this experiment, but this choice of grid can be enriched or modified.
\item The three inner layers have $30$ nodes each, which adding the
  corresponding biases results on a number $$(n+1)\times30+ 3\times
  (1+30)\times 30+(30+1)\times88=30 n+5548$$ of network parameters to
  calibrate.
\item We choose the Elu $\sigma_{\mathrm{Elu}}=\alpha(e^x-1)$ activation
  function for the network.
\end{enumerate}

We train the neural network using gradient descent, the so-called `Adam'
minibatch training scheme due to Kingman and Ba \cite{KBAdam}, which is a
version of the Stochastic Gradient Descent algorithm. In the following, $w$ denotes the set of parameters --
weights and biases -- of a neural network $F = F(w,x)$.  Given parameters
$0 \leq \beta_{1}, \beta_{2} < 1, \epsilon$, $\alpha$, initial iterates
$u_{0} := 0, v_{0} := 0, w_{0}\in\Omega$, the Adam scheme has the following
iterates:
\begin{align*}
  g_{n} &  := \nabla^{w} \sum_{i = 1}^{m}
          \mathcal{L}\left(F(w_{n-1},X_{n,m}^{\text{batch}}),F^*(X_{n,m}^{\text{batch}})\right)\\ 
  u_{n+1} & := \beta_{1} u_{n} + (1 - \beta_{1})g_{n} \\
  v_{n+1} & := \beta_{2} v_{n} + (1 - \beta_{2}) g_{n}^{2} \\
  w_{n+1} & := w_{n} - \alpha \dfrac{u_{n+1}}{1 - \beta_{1}^{n+1}} \dfrac{1}{\sqrt{v_{n} / (1 - \beta_{2}^{n+1})} + \epsilon}.
\end{align*}

\subsection{The calibration step}
\label{sec:calibrationStep}

Once the pricing map approximator $\widetilde{F}$  for the implied volatility
is found, only the calibration step is left to solve. We use the
Levenberg-Marquart algorithm as presented in Section~\ref{sec:an-abstract-view}.


\appendix
\newpage
\begin{thebibliography}{99}
\bibitem{AlosLeon}E. Al\`os, J. Le\'on and J. Vives. 
On the short-time behavior of the implied volatility for jump-diffusion models with stochastic volatility. 
\textit{Finance and Stochastics}, {\tt 11}(4), 571-589, 2007.

\bibitem{AKS19}A. Antonov, M. Konikov, M. Spector.
Modern SABR Analytics: Formulas and Insights for Quants, Former Physicists and Mathematicians.
\textit{SpringerBriefs in Quantitative Finance}, 2019.

\bibitem{ACS99}M. Avellaneda, A. Carelli, F. Stella.
Following the Bayes path to option pricing.
\textit{Journal of Computational Intelligence in Finance}, {\tt 8}4, 1999.

\bibitem{BFGMS17}C.~Bayer, P.~Friz, P.~Gassiat, J.~Martin and B.~Stemper.
A regularity structure for rough volatility. 
\href{https://arxiv.org/abs/1710.07481}{arXiv:1710.07481}, 2017.

\bibitem{BFG15}C.~Bayer, P.~Friz  and J.~Gatheral.
Pricing under rough volatility. 
\textit{Quantitative Finance}, {\tt 16}(6): 1-18, 2016.

\bibitem{BFGHS}C.~Bayer, P. Friz, A. Gulisashvili, B. Horvath and B. Stemper.
Short-time near the money skew in rough fractional stochastic volatility models.
\href{https://arxiv.org/abs/1703.05132}{arXiv:1703.05132}, 2017.

\bibitem{BHMST19}C.~Bayer, B. Horvath, A. Muguruza, B. Stemper and M. Tomas.
On deep calibration of (rough) stochastic volatility models.
\href{https://arxiv.org/abs/1908.08806}{arXiv:1908.08806}, 2019.

\bibitem{BS18}C.~Bayer and B.~Stemper. Deep calibration of rough stochastic volatility models. \textit{Preprint}, \href{https://arxiv.org/pdf/1810.03399.pdf}{arXiv:1810.03399}

\bibitem{BLP16} M.~Bennedsen, A.~Lunde and M.S.~Pakkanen. 
Hybrid scheme for Brownian semistationary processes. 
\textit{Finance and Stochastics}, {\tt 21}(4): 931-965, 2017.

\bibitem{BergomiBook}L.~Bergomi. Stochastic Volatility Modeling.
Chapman \& Hall/CRC financial mathematical series.  \textit{Chapman \& Hall/CRC}, 2015.

\bibitem{OsterleeI} B.~Chen, C.~W. ~Oosterlee and H.~Van~Der~Weide. Efficient unbiased simulation scheme for the SABR stochastic volatility model, 2011.

\bibitem{Cont10}R. Cont.
Model Calibration.
\textit{Encyclopedia of Quantitative Finance},
{\tt 5}, 2010. \href{https://doi.org/10.1002/9780470061602.eqf08002
}{DOI:10.1002/9780470061602.eqf08002}

\bibitem{CulcinDas17}R. Culkin and S. R. Das 
Machine Learning in Finance: The Case of Deep Learning for Option Pricing. 
\textit{Journal of Investment Management}, \href{https:srdas.github.io/Papers/BlackScholesNN.pdf}{github:BlackScholesNN} 2017.

\bibitem{MadanSchoutens} J.~De Spiegeleer, D.~Madan, S.~Reyners and W.~Schoutens. Machine learning for quantitative finance:
Fast derivative pricing, hedging and fitting. \href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3191050}{SSRN:3191050}, 2018.

\bibitem{HestonConvolutional} G.~Dimitroff, D.~R\"oder and C.~P. Fries. Volatility model calibration with convolutional neural networks. \textit{Preprint}, \href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3252432}{SSRN:3252432}, 2018.

\bibitem{DepthNN}R.~Eldan and O.~Shamir. The power of depth for feedforward neural neworks. \textit{JMLR: Workshop and Conference Proceedings} {\tt Vol 49:1-34}, 2016.

\bibitem{ER18}O. El Euch and M. Rosenbaum.
Perfect hedging in rough Heston models, to appear in
\textit{The Annals of Applied Probability}, 2018.

\bibitem{FZ17} M.~Forde, H.~Zhang. Asymptotics for Rough Stochastic Volatility
%  Models, \textit{SIAM Journal on Financial Mathematics} 8(1):114--145, 2017.

\bibitem{StatisticalLearning}J.~Friedman, R.~Tibshiran and  T.~Hastie. The Elements of Statistical Learning. \textit{Springer New York Inc}, 2001.

\bibitem{FG18} R.~Ferguson and A. D.~Green. Deeply learning derivatives.
  Preprint \href{https://arxiv.org/abs/1809.02233}{arXiv:1809.02233}, 2018.

\bibitem{FHLG13} D. Foreman-Mackey, D. W. Hogg, D. Lang, J. Goodman.
  emcee: the MCMC hammer, \emph{Publications of the Astronomical Society of
    the Pacific}, 125(925), 306, 2013.

\bibitem{For16} D. Foreman-Mackey, corner.py: Scatterplot matrices in Python,
  \emph{The Journal of Open Source Software} 24,
  \url{http://dx.doi.org/10.5281/zenodo.45906}, 2016.

\bibitem{Fukasawa}M. Fukasawa.
Asymptotic analysis for stochastic volatility: martingale expansion.
\textit{Finance and Stochastics}, {\tt 15}: 635-654, 2011.

\bibitem{Gat11} J.~Gatheral. The volatility surface: a practitioner's guide,
\textit{Wiley}, 2011.

\bibitem{GJR14}J.~Gatheral, T.~Jaisson  and M.~Rosenbaum.
Volatility is rough.
\textit{Quantitative Finance}, {\tt 18}(6): 933-949, 2018.

\bibitem{Glau19}K. Glau, D. Kressner, and F. Statti.
Low-rank tensor approximation for Chebyshev interpolation in parametric option pricing.
\href{https://arxiv.org/pdf/1902.04367.pdf}{arXiv:1902.04367}, 2019.

\bibitem{Green15}A. Green. XVA: Credit, Funding and Capital Valuation Adjustments. \textit{Wiley}, 2015.

\bibitem{Hagan1}P. Hagan, D. Kumar, A. Lesniewski, and D. Woodward. Managing smile risk. \textit{Wilmott Magazine}, {\tt September issue: 84-108}, 2002.

\bibitem{HJW17}J. Han, A. Jentzen, E. Weinan.
Overcoming the curse of dimensionality: Solving high-dimensional partial differential equations using deep learning.
\textit{PNAS}.{\tt 115}(34) 8505-8510, August 2018.

\bibitem{Hes93}S.L.~Heston. A closed-form solution for options with stochastic
  volatility with applications to bond and currency options, \textit{The Review of Financial Studies} 6(2):327--343, 1993.

\bibitem{Hernandez}A.~Hernandez. Model calibration with neural networks. \textit{Risk}, 2017.    

\bibitem{UniversalApprox}K. Hornik, M. Stinchcombe, and H. White. 
Multilayer feedforward networks are universal approximators. 
\textit{Neural Networks}, {\tt 2}(5):359-366, 1989.

\bibitem{UniversalApproxDerivatives}K.~Hornik. M.~Stinchcombe and H.~White. Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. \textit{Neural Networks}.
Vol. 3:11, 1990.

\bibitem{PHL17}P. Henry-Labord\`{e}re.
Deep primal-dual algorithm for BSDEs: applications of machine learning to CVA and IM. 
\href{https://ssrn.com/abstract=3071506}{SSRN:3071506}

\bibitem{HJM17}B.~Horvath, A.~Jacquier and A.~Muguruza.
Functional central limit theorems for rough volatility.
\href{https://arxiv.org/abs/1711.03078}{arXiv:1711.03078}, 2017.

\bibitem{HMM19}B.~Horvath,  A.~Muguruza and T.~Mehdi.
Deep learning volatility: a deep neural network perspective on pricing and calibration in (rough) volatility models
\textit{Quantitative Finance} 21(1), {\tt p. 11-27}, 2020.

\bibitem{Hutchison94}
J. M. Hutchinson, A. W. Lo and T. Poggio.
A Nonparametric Approach to Pricing and Hedging Derivative Securities Via Learning Networks.
\textit{The Journal of Finance}, {\tt 49}(3) 851-889. \textit{Papers and Proceedings Fifty-Fourth Annual Meeting of the American Finance Association, Boston, Massachusetts}, 1994.

\bibitem{Itkin14} A. Itkin.
To sigmoid-based functional description of the volatility smile.
\textit{Preprint}, \href{https://arxiv.org/pdf/1407.0256.pdf}{arXiv:1407.0256}, 2014. 

\bibitem{IS15}S. Ioffe and C. Szegedy.
Batch normalisation: Accelerating deep network training by reducing internal covariate shift. \textit{Preprint}, \href{https://arxiv.org/abs/1502.03167}{arXiv:1502.03167}, 2015.

\bibitem{KBAdam} D.P.~Kingman and J.~Ba, Adam: A Method for Stochastic Optimization. \textit{Conference paper}, 3rd International Conference for Learning Representations, 2015.

\bibitem{OsterleeII} A.~Leitao~Rodriguez, L.A.~Grzelak and C.W.~Oosterlee. On an efficient multiple time step Monte Carlo simulation of the SABR model. \textit{Quantitative Finance}, {\tt 17}(10), pp.1549-1565, 2017.

\bibitem{Levenberg} K.~Levenberg. A Method for the Solution of Certain Non-Linear Problems in Least Squares. \textit{Quarterly of Applied Mathematics}. 2: pp. 164-168, 1944.
\bibitem{Marquardt} D.~Marquardt. An Algorithm for Least-Squares Estimation of Nonlinear Parameters. \textit{SIAM Journal on Applied Mathematics}. 11 (2): pp. 431-441,1963.`

\bibitem{LiuGrezakOosterlee} S. Liu, A. Borovykh, L. A. Grzelak, C. W. Oosterlee.
A neural network-based framework for financial model calibration.
Preprint, \href{https://arxiv.org/abs/1904.10523}{arXiv:1904.10523}, 2019.

\bibitem{Ludkovski} M. Ludkovski.
Statistical Machine Learning for Quantitative Finance.
\textit{Annual review of statistics and its applications}, {\tt 10}, pp. 271-295, 2023.

\bibitem{McGhee}W.~A.~McGhee. An artificial neural network representation of the SABR stochastic volatility model. \textit{Preprint}, \href{https://ssrn.com/abstract=3288882}{SSRN:3288882}, 2018.

\bibitem{MP18} R.~McCrickerd, M.~Pakkanen, Turbocharging Monte Carlo pricing for the rough Bergomi model, \textit{Quantitative Finance} 18(11):1877-1886, 2018.

\bibitem{RGLO17}A. Leitao Rodriguez, A. Grzelak Lech, Cornelis W. Oosterlee.
On a one time-step Monte Carlo simulation approach of the SABR model : Application to European options.
\textit{Applied Mathematics and Computation}, {\tt 293} p. 461-479, 2017,

\bibitem{SSSz18} M. Sabate Vidales, D. Siska, L. Szpruch
Unbiased deep solvers for parametric PDEs
\href{https://arxiv.org/abs/1810.05094}{arXiv:1810.05094}, 2018.


\bibitem{SS18}J. Sirignano and K. Spiliopoulos.
DGM: A deep learning algorithm for solving partial differential equations.
\textit{Journal of Computational Physics}
{\tt 375}(15) 1339-1364, December 2018

\bibitem{SW2011} L.~Setayeshgar, and H.~Wang. Large deviations for a feed-forward network, \textit{Advances in Applied Probability}, 43: 2, pp. 545-571, 2011.

\bibitem{ShaClCo18}U. Shaham, A. Cloninger, and R. R. Coifman. 
Provable approximation properties for deep neural networks. 
\textit{Appl. Comput. Harmon. Anal.}, {\tt 44}(3): 537-557, 2018.

\bibitem{Stone}H. Stone. Calibrating rough volatility models: a convolutional neural network approach. \textit{Preprint}, \href{https://arxiv.org/pdf/1812.05315.pdf}{arXiv:1812.05315}, 2018.
\end{thebibliography}
\end{document}
